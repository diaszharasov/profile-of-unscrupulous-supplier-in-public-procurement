{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72461a0e-9328-48d5-a2d5-c4bf3ad02925",
   "metadata": {},
   "source": [
    "# Как парсил данные по характеристикам компаний из СПАРК"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b6aedf-487b-4310-9a33-7cd5e639bd1b",
   "metadata": {},
   "source": [
    "> Парсинг проводился по XML файлам из базы СПАРК\n",
    "\n",
    "> XML файлы по конкретным поставщикам (ИНН из РНП)\n",
    "\n",
    "> В доступе были наборы по ИП и по ЮЛ (по ЮЛ более подробная информация)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec005f5-3257-4743-a5d5-5ba773bfb970",
   "metadata": {},
   "source": [
    "## Необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebf4fd1-2bf3-447f-8d40-80c3b7c72584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для работы с XML\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import os\n",
    "# для визуального отслеживания прогресса длительных операций\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69afee6c-99e9-4c6b-8d1e-38cf95f85ba5",
   "metadata": {},
   "source": [
    "## Парсим данные по ИП"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25e5ca5e-8428-46d1-b470-4726582ef3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_to_df(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        xml_content = file.read()\n",
    "        data = xmltodict.parse(xml_content).get('Response', {}).get('Data', {})\n",
    "    \n",
    "    report = data.get('Report', {})\n",
    "    reg_date_spark = report.get('DateReg', 'N/A')\n",
    "    inn_spark = report.get('INN', 'N/A')\n",
    "    region_name_spark = report.get('OKATO', {}).get('@RegionName', 'N/A')\n",
    "    region_code_spark = report.get('OKATO', {}).get('@RegionCode', 'N/A')\n",
    "    \n",
    "    # Проверка и обработка структуры OKVED\n",
    "    okved_data = report.get('OKVED2List', {}).get('OKVED', {})\n",
    "    if isinstance(okved_data, list):\n",
    "        main_okved_code_spark = okved_data[0].get('@Code', 'N/A') if okved_data else 'N/A'\n",
    "        main_okved_name_spark = okved_data[0].get('@Name', 'N/A') if okved_data else 'N/A'\n",
    "    elif isinstance(okved_data, dict):\n",
    "        main_okved_code_spark = okved_data.get('@Code', 'N/A')\n",
    "        main_okved_name_spark = okved_data.get('@Name', 'N/A')\n",
    "    else:\n",
    "        main_okved_code_spark = 'N/A'\n",
    "        main_okved_name_spark = 'N/A'\n",
    "\n",
    "    df_spark = pd.DataFrame({\n",
    "        'reg_date': [reg_date_spark],\n",
    "        'inn': [inn_spark],\n",
    "        'region_name': [region_name_spark],\n",
    "        'region_code': [region_code_spark],\n",
    "        'main_okved_code': [main_okved_code_spark],\n",
    "        'main_okved_name': [main_okved_name_spark]\n",
    "    })\n",
    "    \n",
    "    # Обработка данных по законам\n",
    "    laws_data = {}\n",
    "    state_contracts = data.get('Report', {}).get('StateContracts', {})\n",
    "    for law, law_data in state_contracts.items():\n",
    "        year_info_list = law_data.get('Year', [])\n",
    "        if not isinstance(year_info_list, list):\n",
    "            year_info_list = [year_info_list]  # Превращаем в список, если это одиночный объект\n",
    "        for year_info in year_info_list:\n",
    "            year = year_info.get('@Year', 'N/A')\n",
    "            contracts = year_info.get('Contracts', {})\n",
    "            signed_number = contracts.get('@SignedNumber', 'N/A')\n",
    "            sum_contracts = contracts.get('@Sum', 'N/A')\n",
    "            laws_data[f'{law}_{year}_SignedNumber'] = signed_number\n",
    "            laws_data[f'{law}_{year}_Sum'] = sum_contracts\n",
    "\n",
    "    df_laws = pd.DataFrame([laws_data])\n",
    "\n",
    "    final_df = pd.concat([df_spark, df_laws], axis=1)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def process_all_xml_files(directory):\n",
    "    all_files_df = pd.DataFrame()\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                df = read_xml_to_df(file_path)\n",
    "                all_files_df = pd.concat([all_files_df, df], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "    \n",
    "    return all_files_df\n",
    "\n",
    "# Директория с XML файлами\n",
    "directory_path = r'D:\\Jupyter_Notebook\\2024_ИПС_Данные\\SPARK\\GetEntrepreneurShortReport'\n",
    "\n",
    "# Обработка всех XML файлов и создание общего DataFrame\n",
    "df = process_all_xml_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b1ec4ac-1531-4e7d-ad1b-5357c96f9ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('enterpreneurs_spark_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79061816-c134-4294-9286-fc5b5dabf75b",
   "metadata": {},
   "source": [
    "## Парсим данные по ЮЛ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e265069f-7580-43b1-9028-e26bceaf86a2",
   "metadata": {},
   "source": [
    "Будет 3 датасета для ЮЛ:\n",
    "1) ИНН + общая информация (ОКВЭД, регион)\n",
    "2) ИНН + кол-во сотрудников за каждый год (формат: ИНН-год-число)\n",
    "3) ИНН + фин. показатели из GetCompanyAccountingReport (формат: ИНН-год-фин.показатели)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4be7e-8234-4131-9f63-b2668cc4e158",
   "metadata": {},
   "source": [
    "#### 1 - ИНН + общая информация (ОКВЭД, регион)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54eb660-6224-4d43-a872-85c0111a1173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process 7734001829.xml: 'list' object has no attribute 'get'\n"
     ]
    }
   ],
   "source": [
    "def read_xml_to_df(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        xml_content = file.read()\n",
    "        data = xmltodict.parse(xml_content)['Response']['Data']['Report']\n",
    "    \n",
    "    reg_date_spark = data.get('DateFirstReg', 'N/A')\n",
    "    shortname_spark = data.get('ShortNameRus', 'N/A')\n",
    "    inn_spark = data.get('INN', 'N/A')\n",
    "    kpp_spark = data.get('KPP', 'N/A')\n",
    "    region_name_spark = data['OKATO'].get('@RegionName', 'N/A') if 'OKATO' in data else 'N/A'\n",
    "    region_code_spark = data['OKATO'].get('@RegionCode', 'N/A') if 'OKATO' in data else 'N/A'\n",
    "    \n",
    "    # Обработка OKVED2List как списка или одиночного элемента\n",
    "    okved_data = data.get('OKVED2List', {}).get('OKVED', {})\n",
    "    if isinstance(okved_data, list):\n",
    "        main_okved_code_spark = okved_data[0].get('@Code', 'N/A') if okved_data else 'N/A'\n",
    "        main_okved_name_spark = okved_data[0].get('@Name', 'N/A') if okved_data else 'N/A'\n",
    "    elif isinstance(okved_data, dict):\n",
    "        main_okved_code_spark = okved_data.get('@Code', 'N/A')\n",
    "        main_okved_name_spark = okved_data.get('@Name', 'N/A')\n",
    "    else:\n",
    "        main_okved_code_spark = 'N/A'\n",
    "        main_okved_name_spark = 'N/A'\n",
    "\n",
    "    df_spark = pd.DataFrame({\n",
    "        'reg_date': [reg_date_spark],\n",
    "        'shortname': [shortname_spark],\n",
    "        'inn': [inn_spark],\n",
    "        'kpp': [kpp_spark],\n",
    "        'region_name': [region_name_spark],\n",
    "        'region_code': [region_code_spark],\n",
    "        'main_okved_code': [main_okved_code_spark],\n",
    "        'main_okved_name': [main_okved_name_spark]\n",
    "    })\n",
    "\n",
    "    # Обработка данных по законам\n",
    "    laws_data = {}\n",
    "    state_contracts = data.get('StateContracts', {})\n",
    "    for law, law_data in state_contracts.items():\n",
    "        year_info_list = law_data.get('Year', [])\n",
    "        if not isinstance(year_info_list, list):\n",
    "            year_info_list = [year_info_list]  # Превращаем в список, если это одиночный объект\n",
    "        for year_info in year_info_list:\n",
    "            year = year_info.get('@Year', 'N/A')\n",
    "            contracts = year_info.get('Contracts', {})\n",
    "            signed_number = contracts.get('@SignedNumber', 'N/A')\n",
    "            sum_contracts = contracts.get('@Sum', 'N/A')\n",
    "            laws_data[f'{law}_{year}_SignedNumber'] = signed_number\n",
    "            laws_data[f'{law}_{year}_Sum'] = sum_contracts\n",
    "\n",
    "    df_laws = pd.DataFrame([laws_data])\n",
    "\n",
    "    final_df = pd.concat([df_spark, df_laws], axis=1)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def process_all_xml_files(directory):\n",
    "    all_files_df = pd.DataFrame()\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                df = read_xml_to_df(file_path)\n",
    "                all_files_df = pd.concat([all_files_df, df], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "    \n",
    "    return all_files_df\n",
    "\n",
    "# Директория с XML файлами\n",
    "directory_path = r'D:\\Jupyter_Notebook\\2024_ИПС_Данные\\SPARK\\GetCompanyExtendedReport'\n",
    "\n",
    "# Обработка всех XML файлов и создание общего DataFrame\n",
    "df_comp_main_info = process_all_xml_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e1324b-40d0-4731-ac89-ab2a04327476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comp_main_info.to_csv('comp_main_spark_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250133a4-e106-4878-9e70-83cbfcba50b2",
   "metadata": {},
   "source": [
    "#### 2 - ИНН + кол-во сотрудников за каждый год (формат: ИНН-год-число)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3417103-0708-4cd3-aa15-948e16f28ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_to_df(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        xml_content = file.read()\n",
    "        data = xmltodict.parse(xml_content).get('Response', {}).get('Data', {}).get('Report', {})\n",
    "    \n",
    "    inn_spark = data.get('INN', 'N/A')\n",
    "\n",
    "    employees_list = data.get('StaffNumberFTS', {}).get('Number', [])\n",
    "    if isinstance(employees_list, dict):  # Если есть только одна запись, преобразуем в список\n",
    "        employees_list = [employees_list]\n",
    "\n",
    "    rows = []\n",
    "    for employee in employees_list:\n",
    "        year_spark = employee.get('@ActualDate', 'N/A')[:4]  # Получаем только год из даты\n",
    "        employees_spark = employee.get('#text', 'N/A')\n",
    "        rows.append({\n",
    "            'inn': inn_spark,\n",
    "            'year': year_spark,\n",
    "            'employees': employees_spark\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def process_all_xml_files(directory):\n",
    "    all_files_df = pd.DataFrame()\n",
    "    \n",
    "    files = [f for f in os.listdir(directory) if f.endswith(\".xml\")]\n",
    "    for filename in tqdm(files, desc=\"Processing XML files\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            df = read_xml_to_df(file_path)\n",
    "            all_files_df = pd.concat([all_files_df, df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {filename}: {e}\")\n",
    "    \n",
    "    return all_files_df\n",
    "\n",
    "# Директория с XML файлами\n",
    "directory_path = r'D:\\Jupyter_Notebook\\2024_ИПС_Данные\\SPARK\\GetCompanyExtendedReport'\n",
    "\n",
    "# Обработка всех XML файлов и создание общего DataFrame\n",
    "df_comp_empl_info = process_all_xml_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00fb1f57-37b3-4598-9e56-725ce9901a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_empl_info.to_csv('comp_empl_spark_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee43cbe5-cc93-4f55-b12f-ed4b50bcaef1",
   "metadata": {},
   "source": [
    "#### 3 - ИНН + фин. показатели из GetCompanyAccountingReport (формат: ИНН-год-фин.показатели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c643e86-7eac-40b1-bba0-9f0fe6a26822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing XML files: 100%|█████████████████████████████████████████████████| 213462/213462 [26:11:18<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_xml_to_df(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        xml_content = file.read()\n",
    "        data = xmltodict.parse(xml_content).get('Response', {}).get('Data', {}).get('Report', {})\n",
    "    \n",
    "    inn = data.get('INN', 'N/A')\n",
    "    period_data = data.get('Period', {})\n",
    "    year = period_data.get('@PeriodName', 'N/A')\n",
    "    forms = period_data.get('Form', [])\n",
    "    \n",
    "    if isinstance(forms, dict):  # Если Form представлен одним словарем, обернем его в список\n",
    "        forms = [forms]\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['INN'] = inn\n",
    "    metrics['Year'] = year\n",
    "    seen_names = set()  # Для отслеживания уникальных названий показателей\n",
    "\n",
    "    for form in forms:\n",
    "        power = float(form.get('@Power', 1))  # Получаем множитель и по умолчанию ставим 1\n",
    "        values = form.get('Value', [])\n",
    "        \n",
    "        if isinstance(values, dict):  # Если Value представлен одним словарем, обернем его в список\n",
    "            values = [values]\n",
    "        \n",
    "        for value in values:\n",
    "            metric_name = value.get('@Name')\n",
    "            if metric_name not in seen_names:  # Учитываем только первое вхождение каждого показателя\n",
    "                seen_names.add(metric_name)\n",
    "                metric_value = float(value.get('#text', 0)) * power\n",
    "                metrics[metric_name] = metric_value\n",
    "\n",
    "    df_financial = pd.DataFrame([metrics])  # Создаем DataFrame из словаря, чтобы каждый ключ стал столбцом\n",
    "    \n",
    "    return df_financial\n",
    "\n",
    "def process_all_xml_files(directory):\n",
    "    all_files_df = pd.DataFrame()\n",
    "    \n",
    "    files = [f for f in os.listdir(directory) if f.endswith(\".xml\")]\n",
    "    for filename in tqdm(files, desc=\"Processing XML files\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            df = read_xml_to_df(file_path)\n",
    "            all_files_df = pd.concat([all_files_df, df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {filename}: {e}\")\n",
    "    \n",
    "    return all_files_df\n",
    "\n",
    "# Директория с XML файлами\n",
    "directory_path = r'D:\\Jupyter_Notebook\\2024_ИПС_Данные\\SPARK\\GetCompanyAccountingReport\\GetCompanyAccountingReport'\n",
    "\n",
    "# Обработка всех XML файлов и создание общего DataFrame\n",
    "df_comp_fin_info = process_all_xml_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5105af53-a4d0-4311-aafa-3f26629866ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_fin_info.to_csv('comp_fin_spark_info.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
